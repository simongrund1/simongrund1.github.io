<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Simon Grund</title>
    <link>/</link>
    <description>Recent content on Simon Grund</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Jan 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Missing data in multilevel research</title>
      <link>/publications/2019-chap-apa/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/publications/2019-chap-apa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiple imputation for three-level and cross-classified data</title>
      <link>/posts/multiple-imputation-for-three-level-and-cross-classified-data/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/multiple-imputation-for-three-level-and-cross-classified-data/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Multiple imputation (MI) of missing values in hierarchical data can be tricky when the data do not have a simple two-level structure.
In such a case, understanding and accounting for the hierarchical structure of the data can be challenging, and tools to handle these types of data are relatively rare.&lt;/p&gt;
&lt;p&gt;In this post, I show and explain how to conduct MI for three-level and cross-classified data in &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;types-of-hierarchical-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Types of hierarchical data&lt;/h2&gt;
&lt;p&gt;Hierarchical data have a clustered structure in the sense that observations are clustered in higher-level units (e.g., observations in persons, persons in groups).
Here, I consider two types of this: nested and cross-classified data.&lt;/p&gt;
&lt;div id=&#34;nested-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Nested data&lt;/h3&gt;
&lt;p&gt;In nested data, every observation belongs to one and only one higher-level unit.
Two-level data are a simple example for this type data, as shown below for six clusters with &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; observations.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;460.8&#34; /&gt;&lt;/p&gt;
&lt;p&gt;More deeply nested structures are possible.
For example, in three-level data, the clusters themselves are nested in even-higher-level units (e.g., students nested in classrooms nested in schools).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/figure-html/thumbnail-1.png&#34; width=&#34;460.8&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here, observations &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; are nested within clusters &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt;, and clusters are nested within higher-level clusters &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cross-classified-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cross-classified data&lt;/h3&gt;
&lt;p&gt;In cross-classified data, every observation belongs directly to two or more clusters at once (e.g., experimental data with observations clustered within subjects &lt;em&gt;and&lt;/em&gt; stimuli).
However, the clusters are not themselves nested within one another but “crossed” as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;460.8&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In contrast to nested data, there is no clear hierarchy of the two cluster variables.
Differently put, although both &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; have observations clustered within them, neither of the two is itself nested within the other.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-bother&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Why bother?&lt;/h3&gt;
&lt;p&gt;For the treatment of missing data, the hierarchical structure must be taken into account when using model-based methods such as MI (&lt;a href=&#34;#Enders2016&#34;&gt;Enders, Mistler, &amp;amp; Keller, 2016&lt;/a&gt;; &lt;a href=&#34;#Ludtke2017&#34;&gt;Lüdtke, Robitzsch, &amp;amp; Grund, 2017&lt;/a&gt;).
This means that we need to acknowledge that, in hierarchical data, variables can vary both within and between clusters, and multiple variables can be related at each level of the structure.&lt;/p&gt;
&lt;p&gt;Several articles have considered the case with two-level data (e.g., the two above).
In the following, I show two examples for how to conduct MI for three-level and cross-classified data in R.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;three-level-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Three-level data&lt;/h2&gt;
&lt;p&gt;Suppose we have data from students (level 1) nested in classrooms (level 2) nested in schools (level 3) on four variables &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are measured at level 1, &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; at level 2, and &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; at level 3.
Consider the following model.
For student &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, classroom &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and school &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_{ijk} = \beta_0 + \beta_1 x_{ijk} + \beta_2 \bar{x}_{\bullet jk} + \beta_3 z_{jk} + \beta_4 \bar{x}_{\bullet \bullet k} + \beta_5 \bar{z}_{\bullet k} + \beta_6 w_k
 + u_{jk} + v_k + e_{ijk} \; ,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_{\bullet jk}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_{\bullet \bullet k}\)&lt;/span&gt; are the classroom and school mean of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bar{z}_{\bullet k}\)&lt;/span&gt; is the school mean of &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(u_{jk}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v_k\)&lt;/span&gt; are random intercepts at the classroom and school level, respectively.
A graphical representation of the model is as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;537.6&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how this model allows (a) for lower-level variables to have variance at the different levels, and (b) for the for the variables to be related to each other to different extents at each level.
These features must be taken into account when conducting MI.&lt;/p&gt;
&lt;div id=&#34;example-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example data&lt;/h3&gt;
&lt;p&gt;For this example, I simulated data with a three-level structure consisting of 50 schools (level 3), five classrooms per school (level 2), and 10 students per classroom (level 1, total &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; = 2500).
The data can be downloaded here (&lt;a href=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/example_3l.csv&#34;&gt;CSV&lt;/a&gt;, &lt;a href=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/example_3l.Rdata&#34;&gt;Rdata&lt;/a&gt;).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
class
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
school
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
y
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
z
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
w
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr grouplength=&#34;3&#34;&gt;
&lt;td colspan=&#34;6&#34; style=&#34;border-bottom: none; display: none;&#34;&gt;
&lt;strong&gt;&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.318
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.261
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.456
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.33
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.251
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.456
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.33
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.648
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.456
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.33
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr grouplength=&#34;3&#34;&gt;
&lt;td colspan=&#34;1&#34; style=&#34;border-bottom: none; text-align: right;&#34;&gt;
&lt;strong&gt;…&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.320
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.33
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.069
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.548
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.33
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.33
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr grouplength=&#34;3&#34;&gt;
&lt;td colspan=&#34;1&#34; style=&#34;border-bottom: none; text-align: right;&#34;&gt;
&lt;strong&gt;…&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.339
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.451
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.630
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.441
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.943
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.630
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.775
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.568
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.630
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Every row corresponds to one student, and the classrooms and schools are numbered consecutively. All variables in the data set contain missing data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple imputation&lt;/h3&gt;
&lt;p&gt;To perform MI, I use the R packages &lt;a href=&#34;https://cran.r-project.org/package=mice&#34;&gt;&lt;code&gt;mice&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/package=miceadds&#34;&gt;&lt;code&gt;miceadds&lt;/code&gt;&lt;/a&gt;.
The &lt;code&gt;mice&lt;/code&gt; package treats missing data by iterating through a sequence of imputation models, thus treating variable after variable in a step-by-step manner (for a general introduction to &lt;code&gt;mice&lt;/code&gt;, see &lt;a href=&#34;#vanBuuren2011&#34;&gt;van Buuren &amp;amp; Groothuis-Oudshoorn, 2011&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The imputation models are set up by defining (a) a &lt;em&gt;method&lt;/em&gt; for each variable, naming the type of model to be used, and (b) a &lt;em&gt;predictor matrix&lt;/em&gt;, naming which predictors (columns) should be used for each variable (rows).
Extracting the defaults provides a good starting point.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mice)
library(miceadds)

# predictor matrix and imputation method (defaults)
predMatrix &amp;lt;- make.predictorMatrix(data = dat)
impMethod &amp;lt;- make.method(data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, &lt;code&gt;mice&lt;/code&gt; uses methods intended for non-hierarchical data.
For multilevel data, we need to ensure that the imputation model takes the multilevel structure into account such that the models will need to include variance components at higher levels and allow for different relations between variables at different levels.&lt;/p&gt;
&lt;div id=&#34;setting-up-imputation-models&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Setting up imputation models&lt;/h4&gt;
&lt;p&gt;To this end, we use (a) the &lt;code&gt;ml.lmer&lt;/code&gt; method from &lt;code&gt;miceadds&lt;/code&gt; to impute the lower-level variables &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, and &lt;code&gt;z&lt;/code&gt;, and (b) the &lt;code&gt;2lonly.norm&lt;/code&gt; method from &lt;code&gt;mice&lt;/code&gt; to impute &lt;code&gt;w&lt;/code&gt; at the “top” of the hierarchy.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# method for lower-level variables (x, y, and z)
impMethod[c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;)] &amp;lt;- &amp;quot;ml.lmer&amp;quot;

# method for variables at top level (w)
impMethod[&amp;quot;w&amp;quot;] &amp;lt;- &amp;quot;2lonly.norm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The two methods require that the hierarchical structure of the imputation model is set up in different ways.
To make this easier, we first remove the cluster indicators from the set of predictors altogether by setting their column values to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# remove indicator variables from predictor matrix
predMatrix[, c(&amp;quot;class&amp;quot;, &amp;quot;school&amp;quot;)] &amp;lt;- 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For variables imputed with &lt;code&gt;2lonly.norm&lt;/code&gt;, the hierarchical structure is relatively simple and can be specified in the predictor matrix by setting the highest-level cluster indicator to &lt;code&gt;-2&lt;/code&gt;.
Here, the “top” indicator is &lt;code&gt;school&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ... specify cluster indicator (2lonly.norm)
predMatrix[&amp;quot;w&amp;quot;, &amp;quot;school&amp;quot;] &amp;lt;- -2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For variables imputed with &lt;code&gt;ml.lmer&lt;/code&gt;, the hierarchical structure can be more complicated and must be set with two additional arguments (i.e., outside the predictor matrix).
First, for all higher-level variables (e.g., &lt;code&gt;z&lt;/code&gt; and &lt;code&gt;w&lt;/code&gt;), we need to specify the level at which the variables are measured (all others are assumed to be measured at level 1).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ... specify levels of higher-level variables
level &amp;lt;- character(ncol(dat))
names(level) &amp;lt;- colnames(dat)

level[&amp;quot;w&amp;quot;] &amp;lt;- &amp;quot;school&amp;quot;
level[&amp;quot;z&amp;quot;] &amp;lt;- &amp;quot;class&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, for each variable, we need to specify the cluster variables that define the hierarchical structure in the imputation model.
By default, this uses a random intercept model with random effects at each of the specified levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ... specify cluster indicators (as list)
cluster &amp;lt;- list()

cluster[[&amp;quot;x&amp;quot;]] &amp;lt;- c(&amp;quot;class&amp;quot;, &amp;quot;school&amp;quot;)
cluster[[&amp;quot;y&amp;quot;]] &amp;lt;- c(&amp;quot;class&amp;quot;, &amp;quot;school&amp;quot;)
cluster[[&amp;quot;z&amp;quot;]] &amp;lt;- c(&amp;quot;school&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that we did not have to specify at which level the variables are meant to predict one another.
This is because both &lt;code&gt;ml.lmer&lt;/code&gt; and &lt;code&gt;2lonly.norm&lt;/code&gt; will calculate and include any aggregates of lower-level variables at higher levels whenever possible, meaning that the relations between variables at different levels are automatically included in the imputation models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;imputation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Imputation&lt;/h4&gt;
&lt;p&gt;To start the imputation, we can now run &lt;code&gt;mice&lt;/code&gt; as follows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# run mice
imp &amp;lt;- mice(dat, method = impMethod, predictorMatrix = predMatrix, maxit = 20,
            m = 20, levels_id = cluster, variables_levels = level)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This generates 20 imputations for the missing data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example analysis&lt;/h3&gt;
&lt;p&gt;I use the R packages &lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;&lt;code&gt;mitml&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/package=lme4&#34;&gt;&lt;code&gt;lme4&lt;/code&gt;&lt;/a&gt; to analyze the imputed data.
First, I extract a list imputed data sets and calculate the cluster means that we need in order to fit the analysis model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mitml)

# create list of imputed data sets
implist &amp;lt;- mids2mitml.list(imp)

# calculate group means
implist &amp;lt;- within(implist, {
  x.cls &amp;lt;- clusterMeans(x, class)
  x.sch &amp;lt;- clusterMeans(x, school)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The analysis model is then fitted with the &lt;code&gt;lme4&lt;/code&gt; package, and the results are pooled with &lt;code&gt;mitml&lt;/code&gt; with the following lines of code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)

# fit model
fit &amp;lt;- with(implist,{
  lmer(y ~ 1 + x + x.cls + x.sch + z + w + (1|class) + (1|school))
})

# pool results
testEstimates(fit, var.comp = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# 
# testEstimates(model = fit, var.comp = TRUE)
# 
# Final parameter estimates and inferences obtained from 20 imputed data sets.
# 
#              Estimate Std.Error   t.value        df   P(&amp;gt;|t|)       RIV       FMI 
# (Intercept)    -0.016     0.083    -0.193  2092.008     0.847     0.105     0.096 
# x               0.191     0.017    10.997   179.755     0.000     0.482     0.333 
# x.cls           0.456     0.056     8.119   294.696     0.000     0.340     0.259 
# x.sch           0.358     0.154     2.324  1614.766     0.020     0.122     0.110 
# z              -0.141     0.028    -5.046   394.655     0.000     0.281     0.223 
# w              -0.069     0.085    -0.810   351.561     0.419     0.303     0.237 
# 
#                             Estimate 
# Intercept~~Intercept|class     0.083 
# Intercept~~Intercept|school    0.252 
# Residual~~Residual             0.312 
# 
# Unadjusted hypothesis test as appropriate in larger samples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These results are very close to the parameters I used to generate the data.
In the next example, we move on to clustered data with a cross-classified structure.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;cross-classified-data-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cross-classified data&lt;/h2&gt;
&lt;p&gt;Suppose that we ran an experiment, in which subjects responded to items or stimuli, and obtained data for three variables &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the outcome at level 1, &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is a binary variable at the item level representing the experimental conditions, and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is a covariate at the person level.
Our model of interest is as follows.
For response &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; of subject &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; on item &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y_{ijk} = \beta_0 + \beta_1 z_j + \beta_2 a_k
 + u_j + v_k + e_{ijk} \; ,
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(u_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v_k\)&lt;/span&gt; denote random effects for subjects and items, respectively.
The model can be illustrated like this.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;537.6&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can see that this model is relatively simple because it does not contain aggregated variables.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;
Nonetheless, it allows for (a) an effect of the experimental condition at the item level, (b) relations with the covariate at the person level, and (c) residual variance in the outcome at the level of items, subjects, and responses (i.e., in the interaction of items and subjects).&lt;/p&gt;
&lt;p&gt;Notice how there is no “third” level in this model.
Instead, the “top” level includes both subjects and items, which are not further nested in one another.&lt;/p&gt;
&lt;div id=&#34;example-data-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example data&lt;/h3&gt;
&lt;p&gt;For this example, I simulated data with a cross-classified structure and a total of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; = 5000 responses (level 1) from 100 subjects (level 2b) to 50 items (level 2a).
The experimental condition (&lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; = 1) comprised all even-numbered items; the control (&lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; = 0) all the odd-numbered items.
The data can be downloaded here (&lt;a href=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/example_cc.csv&#34;&gt;CSV&lt;/a&gt;, &lt;a href=&#34;/posts/multiple-imputation-for-three-level-and-cross-classified-data_files/example_cc.Rdata&#34;&gt;Rdata&lt;/a&gt;).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
item
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
subject
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
y
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
a
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
z
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr grouplength=&#34;3&#34;&gt;
&lt;td colspan=&#34;5&#34; style=&#34;border-bottom: none; display: none;&#34;&gt;
&lt;strong&gt;&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.263
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.18
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.029
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.18
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.18
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr grouplength=&#34;3&#34;&gt;
&lt;td colspan=&#34;1&#34; style=&#34;border-bottom: none; text-align: right;&#34;&gt;
&lt;strong&gt;…&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.285
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
49
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.781
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right; padding-left: 2em;&#34; indentlevel=&#34;1&#34;&gt;
50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.202
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Some of the responses (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) are sporadically missing. In addition, a number of subjects failed to provide data on the subject-level covariate (&lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple imputation&lt;/h3&gt;
&lt;p&gt;The main strategy for MI remains the same as in the previous example.
In order to accommodate the multilevel structure, we again need to ensure that the imputation model allows for the variables to have variance and relations with each other at different levels, with the exception that aggregated variables are not used here (see Footnote &lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;We again start with the default setup and adjust it the way we need to.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create default predictor matrix and imputation methods
predMatrix &amp;lt;- make.predictorMatrix(data = dat)
impMethod &amp;lt;- make.method(data = dat)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;setting-up-imputation-models-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Setting up imputation models&lt;/h4&gt;
&lt;p&gt;In this example, only &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; contain missing data.
For the lower-level variable &lt;code&gt;y&lt;/code&gt;, we again use the &lt;code&gt;ml.lmer&lt;/code&gt; method.
For &lt;code&gt;z&lt;/code&gt;, we use &lt;code&gt;2lonly.norm&lt;/code&gt; because it is located at the “top” of the hierarchy (despite it not being there alone).&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# method for lower-level variables (y)
impMethod[&amp;quot;y&amp;quot;] &amp;lt;- &amp;quot;ml.lmer&amp;quot;

# ... for variables at top level (z)
impMethod[&amp;quot;z&amp;quot;] &amp;lt;- &amp;quot;2lonly.norm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To set up these methods, we begin by removing the cluster indicators from the predictor matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# remove indicator variables from set of predictors
predMatrix[, c(&amp;quot;subject&amp;quot;, &amp;quot;item&amp;quot;)] &amp;lt;- 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For variables imputed with &lt;code&gt;2lonly.norm&lt;/code&gt;, the hierarchical structure is then specified in the predictor matrix by setting its cluster indicator to &lt;code&gt;-2&lt;/code&gt;.
The cluster indicator for &lt;code&gt;z&lt;/code&gt; is &lt;code&gt;subject&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# specify cluster indicator (2lonly.norm)
predMatrix[&amp;quot;z&amp;quot;, &amp;quot;subject&amp;quot;] &amp;lt;- -2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For variables imputed with &lt;code&gt;ml.lmer&lt;/code&gt;, the setup again requires a few extra arguments.
Specifically, we need to specify (a) the level at which the higher-level variables (&lt;code&gt;a&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt;) are measured and (b) the cluster variables that define the clustered structure in the imputation model of &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# specify levels of higher-level variables
level &amp;lt;- character(ncol(dat))
names(level) &amp;lt;- colnames(dat)

level[&amp;quot;a&amp;quot;] &amp;lt;- &amp;quot;item&amp;quot;
level[&amp;quot;z&amp;quot;] &amp;lt;- &amp;quot;subject&amp;quot;

# specify cluster indicators (as list)
cluster &amp;lt;- list()

cluster[[&amp;quot;y&amp;quot;]] &amp;lt;- c(&amp;quot;subject&amp;quot;, &amp;quot;item&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Recall that &lt;code&gt;ml.lmer&lt;/code&gt; and &lt;code&gt;2lonly.norm&lt;/code&gt; automatically calculate and include any aggregated variables in every step of the imputation.
However, in this cross-classified design these aggregates turn out to be constant because every person responds to every item (see Footnote &lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;).
For this reason, the aggregates need to be removed from the imputation model.&lt;/p&gt;
&lt;p&gt;For variables imputed with &lt;code&gt;2lonly.norm&lt;/code&gt;, we can do this by removing variables from the predictor matrix.
For &lt;code&gt;z&lt;/code&gt;, we remove &lt;code&gt;a&lt;/code&gt; from the set of predictors such that &lt;code&gt;z&lt;/code&gt; is only predicted by the subject-level aggregate of &lt;code&gt;y&lt;/code&gt; (but not &lt;code&gt;a&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# remove effect of (average) a on z
predMatrix[&amp;quot;z&amp;quot;, &amp;quot;a&amp;quot;] &amp;lt;- 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For variables imputed with &lt;code&gt;ml.lmer&lt;/code&gt;, this is not done in the predictor matrix but with a global argument when running the imputation.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;imputation-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Imputation&lt;/h4&gt;
&lt;p&gt;To start the imputation, we run &lt;code&gt;mice&lt;/code&gt; as follows.
To turn off the automatic aggregation of variables used by &lt;code&gt;ml.lmer&lt;/code&gt;, I also set the argument &lt;code&gt;aggregate_automatically = FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# run mice
imp &amp;lt;- mice(dat, method = impMethod, predictorMatrix = predMatrix, maxit = 20, 
            m = 20, levels_id = cluster, variables_levels = level,
            aggregate_automatically = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-analysis-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example analysis&lt;/h3&gt;
&lt;p&gt;The analysis of the data is done with &lt;code&gt;lme4&lt;/code&gt; and &lt;code&gt;mitml&lt;/code&gt; as before.
First, we extract the imputed data sets as a list.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create list of imputed data sets
implist &amp;lt;- mids2mitml.list(imp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we fit the analysis model with &lt;code&gt;lme4&lt;/code&gt; and pool the results with &lt;code&gt;mitml&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit model
fit &amp;lt;- with(implist,{
  lmer(y ~ 1 + a + z + (1|item) + (1|subject))
})

# pool results
testEstimates(fit, var.comp = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# 
# testEstimates(model = fit, var.comp = TRUE)
# 
# Final parameter estimates and inferences obtained from 20 imputed data sets.
# 
#                Estimate   Std.Error     t.value          df     P(&amp;gt;|t|)         RIV         FMI 
# (Intercept)      -0.148       0.106      -1.394   57324.620       0.163       0.019       0.018 
# a                 0.656       0.124       5.292 2789469.379       0.000       0.003       0.003 
# z                -0.252       0.075      -3.368     210.939       0.001       0.429       0.307 
# 
#                              Estimate 
# Intercept~~Intercept|subject    0.340 
# Intercept~~Intercept|item       0.187 
# Residual~~Residual              0.460 
# 
# Unadjusted hypothesis test as appropriate in larger samples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results are again close to the true values I used to generate the data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;final-remarks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Final remarks&lt;/h2&gt;
&lt;p&gt;In two examples, I showed how to conduct MI for three-level and cross-classified data in R.
In both cases, the hierarchical structure of the data and the relations that exist between variables at different levels of the structure have to be taken into account in the imputation model.
This ensures that the imputations are in line with the posited structure of the data, without which MI might lead to biased results.
We saw that this requires that we (a) choose appropriate imputation methods for hierarchical data (e.g., those in &lt;code&gt;mice&lt;/code&gt; and &lt;code&gt;miceadds&lt;/code&gt;) and (b) include aggregated versions of variables into the imputation model.&lt;/p&gt;
&lt;p&gt;Notice that, although the two types of hierarchical data are very different, the ideas for treating missing data therein were similar.
This is because, the random effects used to represent the hierarchical structure are &lt;em&gt;additive&lt;/em&gt; in both cases.
In fact, the same techniques can be used to treat missing data in any application where that is the case (e.g., nested data with four or more levels, more complex cross-classification, or a combination of the two).&lt;/p&gt;
&lt;p&gt;The examples presented here used simulated continuous data.
Similar methods are available for binary, ordinal, and (to some extent) polytomous data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#Enders2016&#34;&gt;Enders, Mistler, and Keller (2016)&lt;/a&gt; and &lt;a href=&#34;#Ludtke2017&#34;&gt;Lüdtke, Robitzsch, and Grund (2017)&lt;/a&gt; provide a general introduction to missing data and MI in hierarchical data with an emphasis on two-level data.&lt;/li&gt;
&lt;li&gt;Further examples for the imputation of three-level data with &lt;code&gt;mice&lt;/code&gt; and &lt;code&gt;miceadds&lt;/code&gt; can be found in the &lt;a href=&#34;https://cran.r-project.org/web/packages/miceadds/miceadds.pdf&#34;&gt;documentation&lt;/a&gt; of the &lt;code&gt;miceadds&lt;/code&gt; package.&lt;/li&gt;
&lt;li&gt;The Blimp software (&lt;a href=&#34;#Keller2018&#34;&gt;Keller &amp;amp; Enders, 2018&lt;/a&gt;) also supports MI for three-level data with some examples shown &lt;a href=&#34;http://www.appliedmissingdata.com/multilevel-imputation.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;bib&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul class=&#34;bibliography&#34;&gt;
&lt;li id=&#34;Enders2016&#34;&gt;
Enders, C. K., Mistler, S. A., &amp;amp; Keller, B. T. (2016). Multilevel multiple imputation: A review and evaluation of joint modeling and chained equations imputation. &lt;i&gt;Psychological Methods&lt;/i&gt;, &lt;i&gt;21&lt;/i&gt;, 222–240. &lt;a href=&#34;https://doi.org/10.1037/met0000063&#34;&gt;doi:10.1037/met0000063&lt;/a&gt;
&lt;/li&gt;
&lt;li id=&#34;Keller2018&#34;&gt;
Keller, B. T., &amp;amp; Enders, C. K. (2018). &lt;i&gt;Blimp Software Manual (Version 1.1)&lt;/i&gt;.
&lt;/li&gt;
&lt;li id=&#34;Ludtke2017&#34;&gt;
Lüdtke, O., Robitzsch, A., &amp;amp; Grund, S. (2017). Multiple imputation of missing data in multilevel designs: A comparison of different strategies. &lt;i&gt;Psychological Methods&lt;/i&gt;, &lt;i&gt;22&lt;/i&gt;, 141–165. &lt;a href=&#34;https://doi.org/10.1037/met0000096&#34;&gt;doi:10.1037/met0000096&lt;/a&gt;
&lt;/li&gt;
&lt;li id=&#34;vanBuuren2011&#34;&gt;
van Buuren, S., &amp;amp; Groothuis-Oudshoorn, K. (2011). MICE: Multivariate imputation by chained equations in R. &lt;i&gt;Journal of Statistical Software&lt;/i&gt;, &lt;i&gt;45&lt;/i&gt;(3), 1–67. &lt;a href=&#34;https://doi.org/10.18637/jss.v045.i03&#34;&gt;doi:10.18637/jss.v045.i03&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;In the present case, aggregating &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; is not useful, because all items are answered by all subjects, so that the aggregates of &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; at the person level and &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; at the item level are constant (e.g., every person responds to the same number of items in the experimental and the control condition).
However, aggregated variables can still play a role in cross-classified data.
For example, there can be other variables at level 1 (e.g., a covariate providing information about individual trials) or the experimental manipulation may be applied at level 1 (e.g., if it is applied randomly to items on a trial-by-trial basis).
In such a case, the aggregated of these variables would &lt;em&gt;not&lt;/em&gt; be constant and may need to be taken into account during MI.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;If the item-level variable &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; also had missing data, we would treat it the same way (i.e., with &lt;code&gt;2lonly.norm&lt;/code&gt;) but specify a different cluster indicator in the predictor matrix (i.e., &lt;code&gt;item&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# specify imputation method
impMethod[&amp;quot;a&amp;quot;] &amp;lt;- &amp;quot;2lonly.norm&amp;quot;

# specify cluster indicator
predMatrix[&amp;quot;a&amp;quot;, &amp;quot;item&amp;quot;] &amp;lt;- -2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not needed here because &lt;code&gt;a&lt;/code&gt; has no missing data.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;If there are other variables that need to be aggregated (e.g., other variables at level 1), then the aggregation needs to be done “by hand”, either by calculating the aggregated variables beforehand (if the variables are completely observed) or by using “passive imputation” (if they are incomplete).&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Do seductive details do their damage in the context of graph comprehension? Insights from eye movements</title>
      <link>/publications/inpress-acp/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/inpress-acp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dealing with missing data in ANOVA models</title>
      <link>/posts/anova-with-multiply-imputed-data-sets/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/anova-with-multiply-imputed-data-sets/</guid>
      <description>


&lt;p&gt;The analysis of variance, or ANOVA, is among the most popular methods for analyzing how an outcome variable differs between groups, for example, in observational studies or in experiments with different conditions.&lt;/p&gt;
&lt;p&gt;But how do we conduct the ANOVA when there are missing data?
In this post, I show how to deal with missing data in between- and within-subject designs using multiple imputation (MI) in &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;the-anova-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The ANOVA model&lt;/h2&gt;
&lt;p&gt;In the one-factorial ANOVA, the goal is to investigate whether two or more groups differ with respect to some outcome variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.
The statistical model can be written as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation} \label{model}
y_{ij} = \mu_j + e_{ij} \; ,
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}\)&lt;/span&gt; denotes the value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; for person &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in group &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\mu_j\)&lt;/span&gt; is the mean in group &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;.
The (omnibus) null hypothesis of the ANOVA states that all groups have identical population means.
For three groups, this would mean that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation}
\mu_1 = \mu_2 = \mu_3 \; .
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This hypothesis is tested by looking at whether the differences between groups are larger than what could be expected from the differences within groups.
If this is the case, then we reject the null, and the group means are said to be “significantly” different from one another.&lt;/p&gt;
&lt;p&gt;In the following, we will look at how this hypothesis can be tested when the outcome variable contains missing data.
Let’s illustrate this with an example.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1-between-subjects-anova&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1: between-subjects ANOVA&lt;/h2&gt;
&lt;p&gt;For this example, I simulated some data according to a between-subject design with three groups, &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; = 50 subjects per group, and a “medium” effect size of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; = .25, which roughly corresponds to an &lt;span class=&#34;math inline&#34;&gt;\(R^2=6.8\%\)&lt;/span&gt; &lt;a href=&#34;#Cohen1988&#34;&gt;(Cohen, 1988)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can download the data from this post if you want to reproduce the results (&lt;a href=&#34;/posts/anova-with-multiply-imputed-data-sets_files/example1.csv&#34;&gt;CSV&lt;/a&gt;, &lt;a href=&#34;/posts/anova-with-multiply-imputed-data-sets_files/example1.Rdata&#34;&gt;Rdata&lt;/a&gt;). Here are the first few rows.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;group&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;y&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;x&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.715&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.062&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.120&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.633&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.341&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.176&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.792&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.468&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.243&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The three variables mean the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;group&lt;/code&gt;: the grouping variable&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt;: the outcome variable (with 20.7% missing data)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt;: an additional covariate&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this example, cases with lower values in &lt;code&gt;x&lt;/code&gt; had a higher chance of missing data in &lt;code&gt;y&lt;/code&gt;.
Because &lt;code&gt;x&lt;/code&gt; is also positively correlated with &lt;code&gt;y&lt;/code&gt;, this means that smaller &lt;code&gt;y&lt;/code&gt; values are missing more often than larger ones.&lt;/p&gt;
&lt;div id=&#34;listwise-deletion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Listwise deletion&lt;/h3&gt;
&lt;p&gt;Lets see what happens if we run the ANOVA only with those cases that have &lt;code&gt;y&lt;/code&gt; observed (i.e., listwise deletion). This is the standard setting on most statistical software.&lt;/p&gt;
&lt;p&gt;In R, the ANOVA can be conducted with the &lt;code&gt;lm()&lt;/code&gt; function as follows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit the ANOVA model
fit1 &amp;lt;- lm(y ~ 1 + group, data = dat)
summary(fit1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# lm(formula = y ~ 1 + group, data = dat)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -1.8196 -0.6237 -0.0064  0.5657  2.1808 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(&amp;gt;|t|)
# (Intercept)   0.0944     0.1452    0.65     0.52
# groupB        0.1720     0.1972    0.87     0.38
# groupC       -0.1570     0.2082   -0.75     0.45
# 
# Residual standard error: 0.895 on 116 degrees of freedom
#   (31 observations deleted due to missingness)
# Multiple R-squared:  0.0229,  Adjusted R-squared:  0.00609 
# F-statistic: 1.36 on 2 and 116 DF,  p-value: 0.26&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;-test at the bottom of the output indicates that the group means are &lt;em&gt;not&lt;/em&gt; significantly different from one another, &lt;span class=&#34;math inline&#34;&gt;\(F(\!\)&lt;/span&gt; 2, 116 &lt;span class=&#34;math inline&#34;&gt;\(\!)\)&lt;/span&gt; = 1.361 (&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; = 0.26).&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;
In addition, the effect size (&lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; = 0.023) is quite a bit smaller than what was used to generate the data.&lt;/p&gt;
&lt;p&gt;In fact, this result is a direct consequence of how the missing data were simulated.
Fortunately, there are statistical methods that can account for the missing data and help us obtain more trustworthy results.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-imputation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple imputation&lt;/h3&gt;
&lt;p&gt;One of the most effective ways of dealing with missing data is multiple imputation (MI).
Using MI, we can create multiple plausible replacements of the missing data, given what we have observed and a statistical model (the imputation model).&lt;/p&gt;
&lt;p&gt;In the ANOVA, using MI has the additional benefit that it allows taking covariates into account that are relevant for the missing data but not for the analysis.
In this example, &lt;code&gt;x&lt;/code&gt; is a direct cause of missing data in &lt;code&gt;y&lt;/code&gt;. Therefore, we must take &lt;code&gt;x&lt;/code&gt; into account when making inferences about &lt;code&gt;y&lt;/code&gt; in the ANOVA.&lt;/p&gt;
&lt;p&gt;Running MI consists of three steps. First, the missing data are imputed multiple times. Second, the imputed data sets are analyzed separately. Third, the parameter estimates and hypothesis tests are &lt;em&gt;pooled&lt;/em&gt; to form a final set of estimates and inferences.&lt;/p&gt;
&lt;p&gt;For this example, we will use the &lt;a href=&#34;https://cran.r-project.org/package=mice&#34;&gt;&lt;code&gt;mice&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;&lt;code&gt;mitml&lt;/code&gt;&lt;/a&gt; packages to conduct MI.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mice)
library(mitml)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Specifying an imputation model is very simple here. With the following command, we generate 100 imputations for &lt;code&gt;y&lt;/code&gt; on the basis of a regression model with both &lt;code&gt;group&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; as predictors and a normal error term.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# run MI
imp &amp;lt;- mice(data = dat, method = &amp;quot;norm&amp;quot;, m = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The imputed data sets can then be saved as a list, containing 100 copies of the original data, in which the missing data have been replaced by different imputations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a list of completed data sets
implist &amp;lt;- mids2mitml.list(imp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we fit the ANOVA model to each of the imputed data sets and pool the results.
The analysis part is done with the &lt;code&gt;with()&lt;/code&gt; command, which applies the same linear model, &lt;code&gt;lm()&lt;/code&gt;, to each data set.
The pooling es then done with the &lt;code&gt;testEstimates()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit the ANOVA model
fit2 &amp;lt;- with(implist, lm(y ~ 1 + group))

# pool the parameter estimates
testEstimates(fit2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# 
# testEstimates(model = fit2)
# 
# Final parameter estimates and inferences obtained from 100 imputed data sets.
# 
#              Estimate Std.Error   t.value        df   P(&amp;gt;|t|)       RIV       FMI 
# (Intercept)     0.027     0.144     0.190  3178.456     0.850     0.214     0.177 
# groupB          0.207     0.198     1.044  5853.312     0.297     0.149     0.130 
# groupC         -0.333     0.208    -1.600  2213.214     0.110     0.268     0.212 
# 
# Unadjusted hypothesis test as appropriate in larger samples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that we did not need to actually include &lt;code&gt;x&lt;/code&gt; in the ANOVA.
Rather, it was enough to include &lt;code&gt;x&lt;/code&gt; in the imputation model, after which the analyses proceeded as usual.&lt;/p&gt;
&lt;p&gt;We now have estimated the regression coefficients in the ANOVA model (i.e., the differences between group means), but we have yet to decide whether the means are all equal or not.
To this end, we use a pooled version of the &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;-test above, which consists of a comparison of the full model (the ANOVA model) with a reduced model that does not contain the coefficients we wish to test.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this case, we wish to test the coefficients pertaining to the differences between groups, so the reduced model does not contain &lt;code&gt;group&lt;/code&gt; as a predictor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit the reduced ANOVA model (without &amp;#39;group&amp;#39;)
fit2.reduced &amp;lt;- with(implist, lm(y ~ 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The full and the reduced model can then be compared with the pooled version of the &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;-test (i.e., the Wald test), which is known in the literature as &lt;span class=&#34;math inline&#34;&gt;\(D_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# compare the two models with pooled Wald test
testModels(fit2, fit2.reduced, method = &amp;quot;D1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# 
# testModels(model = fit2, null.model = fit2.reduced, method = &amp;quot;D1&amp;quot;)
# 
# Model comparison calculated from 100 imputed data sets.
# Combination method: D1 
# 
#     F.value      df1      df2    P(&amp;gt;F)      RIV 
#       3.635        2 7186.601    0.026    0.195 
# 
# Unadjusted hypothesis test as appropriate in larger samples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In contrast with listwise deletion, the &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;-test under MI indicates that the groups &lt;em&gt;are&lt;/em&gt; significantly different from one another.&lt;/p&gt;
&lt;p&gt;This is because MI makes use of all the observed data, including the covariate &lt;code&gt;x&lt;/code&gt;, and used this information to generated replacements for missing &lt;code&gt;y&lt;/code&gt; that took its relation with &lt;code&gt;x&lt;/code&gt; into account.
To see this, it is worth looking at a comparison of the observed and the imputed data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/posts/anova-with-multiply-imputed-data-sets_files/figure-html/thumbnail-1.png&#34; width=&#34;691.2&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The difference is not extreme, but it is easy to see that the imputed data tend to have more mass at the lower end of the distribution of &lt;code&gt;y&lt;/code&gt; (especially in groups A and C).&lt;/p&gt;
&lt;p&gt;This is again a result of how the data were simulated: Lower &lt;code&gt;y&lt;/code&gt; values, through their relation with &lt;code&gt;x&lt;/code&gt;, are missing more often, which is accounted for using MI.
Conversely, using listwise deletion placed the group means more closely together than they should be, and this affected the results in the ANOVA.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2-mixedwithin-subjects-anova&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2: mixed/within-subjects ANOVA&lt;/h2&gt;
&lt;p&gt;In a within-subjects design, the design factor varies within (not between) persons, and we obtain multiple, repeated measurements for each condition (mixed designs include both).
Fortunately, the procedure for the treatment and missing data and the analysis remains mostly the same.&lt;/p&gt;
&lt;p&gt;Although within-subjects designs are analyzed most often with the repeated-measures ANOVA, mixed-effects models have become a popular alternative. Here, I will choose the latter because mixed-effects models make it straightforward to pool ANOVA-like hypotheses in within-subjects designs.&lt;/p&gt;
&lt;p&gt;To fit the mixed-effects model, we will use the &lt;code&gt;lmer()&lt;/code&gt; function from the package &lt;a href=&#34;https://cran.r-project.org/package=lme4&#34;&gt;&lt;code&gt;lme4&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I simulated a second data set similar to the one above, with &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; = 20 persons, a within-subject factor with three conditions, and five repeated measurements for each condition (&lt;a href=&#34;/posts/anova-with-multiply-imputed-data-sets_files/example2.csv&#34;&gt;CSV&lt;/a&gt;, &lt;a href=&#34;/posts/anova-with-multiply-imputed-data-sets_files/example2.Rdata&#34;&gt;Rdata&lt;/a&gt;).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;id&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cond&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;y&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;x&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.699&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.022&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.287&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.588&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.028&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.11&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The variables mean the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;id&lt;/code&gt;: the subject identifier&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cond&lt;/code&gt;: the grouping variable (within subjects)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt;: the repeated measurements for the outcome variable (with 18.7% missing data)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt;: a subject-specific covariate&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Like above, persons with lower values in &lt;code&gt;x&lt;/code&gt; had a higher chance of missing data in &lt;code&gt;y&lt;/code&gt;. Notice that &lt;code&gt;cond&lt;/code&gt; varies within subjects, making the repeated measures for each condition “nested” within subjects.&lt;/p&gt;
&lt;div id=&#34;multiple-imputation-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple imputation&lt;/h3&gt;
&lt;p&gt;To properly accommodate the “nested” structure of the repeated measurements, the imputation model can no longer be a simple regression.
Instead, it needs to accommodate this structure by also employing a mixed-effects model.
Specifying this model is easiest by first initializing the imputation model with the default values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# run MI (for starting solution)
ini &amp;lt;- mice(data = dat, maxit = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we define the subject identifier for the imputation model (&lt;code&gt;id&lt;/code&gt;) and change the imputation method to a use a mixed-effects model (&lt;code&gt;&#34;2l.pan&#34;&lt;/code&gt;).
Running MI is then the same as before.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the &amp;#39;subject&amp;#39; identifier (code as &amp;#39;-2&amp;#39; in predictor matrix)
pred &amp;lt;- ini$pred
pred[&amp;quot;y&amp;quot;, &amp;quot;id&amp;quot;] &amp;lt;- -2

# run MI
imp &amp;lt;- mice(data = dat, pred = pred, method = &amp;quot;2l.pan&amp;quot;, m = 100)
summary(imp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The list of imputed data sets is generated as above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a list of completed data sets
implist &amp;lt;- mids2mitml.list(imp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ANOVA model is then fit using &lt;code&gt;lmer()&lt;/code&gt;.
Notice that this model contains an additional term, &lt;code&gt;(1|id)&lt;/code&gt;, which specifies a random effect for each subject.
This effect captures unsystematic differences between subjects, thus accounting for the nested structure of the repeated-measures data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit the ANOVA model
fit3 &amp;lt;- with(implist, lmer(y ~ 1 + cond + (1|id)))
testEstimates(fit3, var.comp = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# 
# testEstimates(model = fit3, var.comp = TRUE)
# 
# Final parameter estimates and inferences obtained from 100 imputed data sets.
# 
#               Estimate  Std.Error    t.value         df    P(&amp;gt;|t|)        RIV        FMI 
# (Intercept)     -0.065      0.227     -0.286 108243.160      0.775      0.031      0.030 
# condB            0.352      0.112      3.151   3197.566      0.002      0.214      0.176 
# condC            0.048      0.114      0.418   2120.953      0.676      0.276      0.217 
# 
#                         Estimate 
# Intercept~~Intercept|id    0.893 
# Residual~~Residual         0.514 
# ICC|id                     0.635 
# 
# Unadjusted hypothesis test as appropriate in larger samples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output is similar to before, with the regression coefficients denoting the differences between the conditions. In addition, the output includes the variance of the random effect that denotes the unsystematic differences between subjects.&lt;/p&gt;
&lt;p&gt;Testing the null hypothesis of the ANOVA again requires the specification of a reduced model that does not contain the parameters to be tested (i.e., those pertaining to &lt;code&gt;cond&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# pool the parameter estimates
fit3.reduced &amp;lt;- with(implist, lmer(y ~ 1 + (1|id)))
testModels(fit3, fit3.reduced, method = &amp;quot;D1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# 
# testModels(model = fit3, null.model = fit3.reduced, method = &amp;quot;D1&amp;quot;)
# 
# Model comparison calculated from 100 imputed data sets.
# Combination method: D1 
# 
#     F.value      df1      df2    P(&amp;gt;F)      RIV 
#       5.681        2 4847.199    0.003    0.248 
# 
# Unadjusted hypothesis test as appropriate in larger samples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As in the first example, the three conditions are significantly different from one another.&lt;/p&gt;
&lt;p&gt;These two examples were obviously very simple.
However, the same general procedure can be used for more complex ANOVA models, including models with two or more factors, interaction effects, or for mixed designs with both between- and within-subject factors.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;procedures-other-than-mi&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Procedures other than MI&lt;/h2&gt;
&lt;p&gt;Imputation is not the only method that can deal with missing data, and other methods like maximum-likelihood estimation (ML) have also been recommended (&lt;a href=&#34;#Schafer2002&#34;&gt;Schafer &amp;amp; Graham, 2002&lt;/a&gt;).
Using ML, cases contribute to the estimation of the model only to the extent to which they have data, and its results are often equally trustworthy as those under MI.&lt;/p&gt;
&lt;p&gt;However, in the ANOVA, this should be taken with a grain of salt.
For missing data in the outcome variable &lt;code&gt;y&lt;/code&gt;, using ML simply means that the model is estimated using only the cases with observed &lt;code&gt;y&lt;/code&gt; (i.e., listwise deletion), which can lead to distorted parameter estimates if other variables are related to the chance of observing &lt;code&gt;y&lt;/code&gt; (see Example 1).
In order to account for this, ML requires including these extra variables in the analysis model, which changes the meaning of the parameters (i.e., the ANOVA becomes ANCOVA, though the estimates for it &lt;em&gt;would&lt;/em&gt; be unbiased!).&lt;/p&gt;
&lt;p&gt;One key advantage of MI is that the treatment of missing data is independent of the analysis.
Variables relevant for the treatment of missing data can be included in the imputation model without altering the analysis model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further reading&lt;/h2&gt;
&lt;p&gt;To read more about ANOVA models and the treatment of missing data therein, you can check the following resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#Maxwell2018&#34;&gt;Maxwell, Delaney, and Kelley (2018)&lt;/a&gt; give a great introduction into the design and analysis of experimental data with the ANOVA and mixed-effects models&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vanGinkel2014&#34;&gt;van Ginkel and Kroonenberg (2014)&lt;/a&gt; provide a detailed discussion of missing data and MI in the ANOVA with examples, syntax files, and a macro for SPSS&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Grund2016&#34;&gt;Grund, Lüdtke, and Robitzsch (2016)&lt;/a&gt; provide a comparison of different methods for testing hypotheses in the ANOVA under MI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Liu2017&#34;&gt;Liu and Enders (2017)&lt;/a&gt; provide a similar comparison in the context of regression analyses&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;bib&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul class=&#34;bibliography&#34;&gt;
&lt;li id=&#34;Cohen1988&#34;&gt;
Cohen, J. (1988). &lt;i&gt;Statistical power analysis for the behavioral sciences&lt;/i&gt; (2nd ed.). Hillsdale, NJ: Erlbaum.
&lt;/li&gt;
&lt;li id=&#34;Grund2016&#34;&gt;
Grund, S., Lüdtke, O., &amp;amp; Robitzsch, A. (2016). Pooling ANOVA results from multiply imputed datasets: A simulation study. &lt;i&gt;Methodology&lt;/i&gt;, &lt;i&gt;12&lt;/i&gt;, 75–88. &lt;a href=&#34;https://doi.org/10.1027/1614-2241/a000111&#34;&gt;doi:10.1027/1614-2241/a000111&lt;/a&gt;
&lt;/li&gt;
&lt;li id=&#34;Liu2017&#34;&gt;
Liu, Y., &amp;amp; Enders, C. K. (2017). Evaluation of multi-parameter test statistics for multiple imputation. &lt;i&gt;Multivariate Behavioral Research&lt;/i&gt;, &lt;i&gt;52&lt;/i&gt;, 371–390. &lt;a href=&#34;https://doi.org/10.1080/00273171.2017.1298432&#34;&gt;doi:10.1080/00273171.2017.1298432&lt;/a&gt;
&lt;/li&gt;
&lt;li id=&#34;Maxwell2018&#34;&gt;
Maxwell, S. E., Delaney, H. D., &amp;amp; Kelley, K. (2018). &lt;i&gt;Designing experiments and analyzing data: A model comparison perspective&lt;/i&gt; (3rd ed.). Mahwah, NJ: Erlbaum.
&lt;/li&gt;
&lt;li id=&#34;Schafer2002&#34;&gt;
Schafer, J. L., &amp;amp; Graham, J. W. (2002). Missing data: Our view of the state of the art. &lt;i&gt;Psychological Methods&lt;/i&gt;, &lt;i&gt;7&lt;/i&gt;, 147–177. &lt;a href=&#34;https://doi.org/10.1037//1082-989X.7.2.147&#34;&gt;doi:10.1037//1082-989X.7.2.147&lt;/a&gt;
&lt;/li&gt;
&lt;li id=&#34;vanGinkel2014&#34;&gt;
van Ginkel, J. R., &amp;amp; Kroonenberg, P. M. (2014). Analysis of variance of multiply imputed data. &lt;i&gt;Multivariate Behavioral Research&lt;/i&gt;, &lt;i&gt;49&lt;/i&gt;, 78–91. &lt;a href=&#34;https://doi.org/10.1080/00273171.2013.855890&#34;&gt;doi:10.1080/00273171.2013.855890&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The hypothesis test in ANOVA is a Wald test that simultaneously tests all the differences between groups against zero. In this example, these differences are represented by the regression coefficients for &lt;code&gt;groupB&lt;/code&gt; and &lt;code&gt;groupC&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This can easily be verified by calculating the Wald test by hand:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# estimates and covariance matrix
b &amp;lt;- coef(fit1)[-1]
V &amp;lt;- vcov(fit1)[-1,-1]

# Wald-test
F &amp;lt;- b %*% solve(V) %*% b / 2      # F statistic
pf(F, 2, 116, lower.tail = FALSE)  # p value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#      [,1]
# [1,] 0.26&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; value are exactly the same as in the output above.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Technically, a reduced model is not necessary (only convenient). The Wald test can be formulated equivalently with a linear constraint on the parameters of the full model (i.e., setting them to zero).&lt;/p&gt;
&lt;p&gt;Under MI, this can be done, too, with the &lt;code&gt;testConstraints()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define and test parameter constraints
con &amp;lt;- c(&amp;quot;groupB&amp;quot;, &amp;quot;groupC&amp;quot;)
testConstraints(fit2, constraints = con, method = &amp;quot;D1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 
# Call:
# 
# testConstraints(model = fit2, constraints = con, method = &amp;quot;D1&amp;quot;)
# 
# Hypothesis test calculated from 100 imputed data sets. The following
# constraints were specified:
# 
#              Estimate Std. Error 
#    groupB:      0.207      0.202 
#    groupC:     -0.333      0.202 
# 
# Combination method: D1 
# 
#     F.value      df1      df2    P(&amp;gt;F)      RIV 
#       3.635        2 7186.601    0.026    0.195 
# 
# Unadjusted hypothesis test as appropriate in larger samples.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results of this are identical to those of &lt;code&gt;testModels()&lt;/code&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Hello, World!</title>
      <link>/posts/hello_world/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/posts/hello_world/</guid>
      <description>


&lt;p&gt;This first post marks the launch of my website, with which I have been tinkering for some time now. From time to time, I will update the blog with new posts about topics related to quantitative psychology, statistical methods, R, Vim, and other things that interest me. So be sure to check back periodically!&lt;/p&gt;
&lt;p&gt;In addition, you can find information about my publications and software projects. Whenever possible, I will update this information, including full-text versions of my articles and links to published and manuscript versions.&lt;/p&gt;
&lt;p&gt;If you have any comments or suggestions for improvements for this website, you’re welcome to drop me a line on Twitter or via &lt;a href=&#34;https://www.ipn.uni-kiel.de/en/the-ipn/departments/research-methodology/staff/grund-simon?set_language=en&#34;&gt;email&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;credit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Credit&lt;/h2&gt;
&lt;p&gt;This website was created with the help of several tools created and made openly available by many wonderful people. It uses &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt; for building and content organization. The theme is based on &lt;a href=&#34;https://themes.gohugo.io/hyde/&#34;&gt;Hyde&lt;/a&gt; with some alterations and redesigns inspired by the &lt;a href=&#34;https://github.com/morhetz/gruvbox&#34;&gt;gruvbox&lt;/a&gt; color scheme. Display of math symbols is powered by &lt;a href=&#34;https://www.mathjax.org/&#34;&gt;MathJax&lt;/a&gt;, and icons by &lt;a href=&#34;https://fontawesome.com/&#34;&gt;Font Awesome&lt;/a&gt; and &lt;a href=&#34;https://jpswalsh.github.io/academicons/&#34;&gt;Academicons&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multiple imputation of missing data at level 2: A comparison of fully conditional and joint modeling in multilevel designs</title>
      <link>/publications/2018-jebs/</link>
      <pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2018-jebs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiple imputation of missing data for multilevel models: Simulations and recommendations</title>
      <link>/publications/2018-orm/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2018-orm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The merits of representational pictures in educational assessment: Evidence for cognitive and motivational effects in a time-on-task analysis</title>
      <link>/publications/2017-cep/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2017-cep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiple imputation of missing data in multilevel designs: A comparison of different strategies</title>
      <link>/publications/2017-pm/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2017-pm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pooling ANOVA results from multiply imputed datasets: A simulation study</title>
      <link>/publications/2016-methodology/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2016-methodology/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiple imputation of multilevel missing data: An introduction to the R package pan</title>
      <link>/publications/2016-sageopen/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2016-sageopen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiple imputation of missing covariate values in multilevel models with random slopes: A cautionary note</title>
      <link>/publications/2016-brm/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/publications/2016-brm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>mitml</title>
      <link>/software/mitml/</link>
      <pubDate>Tue, 01 May 2018 22:16:00 +0200</pubDate>
      
      <guid>/software/mitml/</guid>
      <description>

&lt;p&gt;This &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt; package provides tools for multiple imputation of missing data in multilevel modeling.
It includes a user-friendly interface to the packages &lt;code&gt;pan&lt;/code&gt; and &lt;code&gt;jomo&lt;/code&gt;, and several functions for visualization, data management, and the analysis of multiply imputed data sets.&lt;/p&gt;

&lt;p&gt;The purpose of &lt;code&gt;mitml&lt;/code&gt; is to provide users with a set of effective and user-friendly tools for multiple imputation of multilevel data without requiring advanced knowledge of its statistical underpinnings.
Examples and additional information can be found in the official &lt;a href=&#34;https://cran.r-project.org/package=mitml/mitml.pdf&#34;&gt;documentation&lt;/a&gt; of the package and in the &lt;a href=&#34;https://github.com/simongrund1/mitml/wiki&#34;&gt;Wiki&lt;/a&gt; pages on GitHub.&lt;/p&gt;

&lt;h4 id=&#34;cran-version&#34;&gt;CRAN version&lt;/h4&gt;

&lt;p&gt;The official version of &lt;code&gt;mitml&lt;/code&gt; is hosted on CRAN and may be found &lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;here&lt;/a&gt;. The CRAN version can be installed from within R using:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;mitml&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;github-version&#34;&gt;GitHub version&lt;/h4&gt;

&lt;p&gt;The development version of &lt;code&gt;mitml&lt;/code&gt; is hosted on GitHub, allowing better tracking of &lt;a href=&#34;https://github.com/simongrund1/mitml/issues&#34;&gt;issues&lt;/a&gt; and possibly containing features and changes in advance. The GitHub version can be installed using &lt;code&gt;devtools&lt;/code&gt; as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;devtools&amp;quot;)
devtools::install_github(&amp;quot;simongrund1/mitml&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;documentation-pdf&#34;&gt;Documentation (PDF)&lt;/h4&gt;

&lt;p&gt;The official &lt;a href=&#34;https://cran.r-project.org/web/packages/mitml/mitml.pdf&#34;&gt;documentation&lt;/a&gt; of the package can be found on &lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;CRAN&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;vignettes-html&#34;&gt;Vignettes (HTML)&lt;/h4&gt;

&lt;p&gt;Further examples and documentation are provided in HTML vignettes on &lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;CRAN&lt;/a&gt; and on the follwing pages.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cdn.rawgit.com/simongrund1/mitml/abdc7d58/vignettes/Introduction.html&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cdn.rawgit.com/simongrund1/mitml/abdc7d58/vignettes/Level2.html&#34;&gt;Imputation of missing data at Level 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cdn.rawgit.com/simongrund1/mitml/abdc7d58/vignettes/Analysis.html&#34;&gt;Analysis of multiply imputed data sets&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you use &lt;code&gt;mitml&lt;/code&gt; and have suggestions for improvement, please email me (see &lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;here&lt;/a&gt;) or file an &lt;a href=&#34;https://github.com/simongrund1/mitml/issues&#34;&gt;issue&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;&lt;img src=&#34;http://www.r-pkg.org/badges/version/mitml&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;a href=&#34;https://cran.r-project.org/package=mitml&#34;&gt;&lt;img src=&#34;http://cranlogs.r-pkg.org/badges/mitml&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
